{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train-mask-detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soOetXKz0Jt2",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_IGvnYFz9NM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVYk8-8b2q0C",
        "colab_type": "text"
      },
      "source": [
        "## Setup notebook parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddIhdddt2xjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train parameters\n",
        "INIT_LEARNING_RATE = 1e-4\n",
        "EPOCHS             = 20\n",
        "BATCH_SIZE         = 32\n",
        "\n",
        "# Data parameters\n",
        "root_path  = '/content/drive/My Drive/covid-19/'\n",
        "data_path  = root_path + 'dataset/'\n",
        "model_path = root_path + 'detection_mask_model'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icj9GBio2g74",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk__D0O02j8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_paths():\n",
        "  file_paths_and_labels = []\n",
        "  subfolders            = [x[0] for x in os.walk(data_path)][1:]\n",
        "  \n",
        "  for folder in subfolders:\n",
        "    label = folder.split('/')[-1]\n",
        "    \n",
        "    [file_paths_and_labels.append((folder + '/' + file_name, label)) for file_name in os.listdir(folder)]\n",
        "\n",
        "  return file_paths_and_labels\n",
        "\n",
        "def load_images():\n",
        "  file_paths_and_labels = load_image_paths()\n",
        "  data   = []\n",
        "  labels = []\n",
        "  \n",
        "  total_images = len(file_paths_and_labels)\n",
        "\n",
        "  for i, (image_path, label) in enumerate(file_paths_and_labels):\n",
        "    print(\"Loading images: %.2f%%\" % (100*(i+1)/total_images))\n",
        "\n",
        "    image = load_img(image_path, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = preprocess_input(image)\n",
        "\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        "  \n",
        "  data   = np.array(data, dtype=\"float32\")\n",
        "  labels = np.array(labels)\n",
        "  \n",
        "  return data, labels\n",
        "\n",
        "data, labels = load_images()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSQIxXmaGhj3",
        "colab_type": "text"
      },
      "source": [
        "## One-Hot encoding, Data split (train/test) and Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx91hC-MGvLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "labels          = to_categorical(label_binarizer.fit_transform(labels))\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, \n",
        "                                                  labels, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  test_size\t\t = 0.20, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tstratify\t\t = labels, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\trandom_state = 7)\n",
        "\n",
        "augmentation_params = ImageDataGenerator(rotation_range \t\t= 20,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t zoom_range \t\t\t\t= 0.15,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t width_shift_range \t= 0.2,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t height_shift_range = 0.2,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t shear_range \t\t\t\t= 0.15,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t horizontal_flip \t\t= True,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t fill_mode \t\t\t\t\t= \"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3E2QPe_LH8t",
        "colab_type": "text"
      },
      "source": [
        "## Load Pre-trained model and implement the custom model layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFy3DH0oLzPl",
        "colab_type": "code",
        "outputId": "2d232c36-7d8f-43d7-cbf8-f38135a939a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "head_model = MobileNetV2(weights      = \"imagenet\", \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t include_top  = False, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t input_tensor = Input(shape=(224, 224, 3)))\n",
        "\n",
        "base_model = head_model.output\n",
        "base_model = AveragePooling2D(pool_size=(7, 7))(base_model)\n",
        "base_model = Flatten(name=\"flatten\")(base_model)\n",
        "base_model = Dense(128, activation=\"relu\")(base_model)\n",
        "base_model = Dropout(0.5)(base_model)\n",
        "base_model = Dense(2, activation=\"softmax\")(base_model)\n",
        "\n",
        "model = Model(inputs=head_model.input, outputs=base_model)\n",
        "\n",
        "for layer in head_model.layers:\n",
        "\tlayer.trainable = False"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cz8fZb-NagZ",
        "colab_type": "text"
      },
      "source": [
        "## Compile and train model head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtuWKdpJNdYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Adam(lr=INIT_LEARNING_RATE, decay=INIT_LEARNING_RATE / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
        "\tsteps_per_epoch=len(trainX) // BATCH_SIZE,\n",
        "\tvalidation_split = 0.2,\n",
        "\tvalidation_steps=len(testX) // BATCH_SIZE,\n",
        "\tepochs=EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvBQLvoTOSvy",
        "colab_type": "text"
      },
      "source": [
        "## Model validation And Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Kjs1m5OUib",
        "colab_type": "code",
        "outputId": "50d29e85-dddd-4c38-9961-8e5d23ccffd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "predIdxs = model.predict(testX, batch_size=BATCH_SIZE)\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
        "\ttarget_names=label_binarizer.classes_))\n",
        "\n",
        "model.save(model_path, save_format=\"h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   with_mask       1.00      1.00      1.00       138\n",
            "without_mask       1.00      1.00      1.00       139\n",
            "\n",
            "    accuracy                           1.00       277\n",
            "   macro avg       1.00      1.00      1.00       277\n",
            "weighted avg       1.00      1.00      1.00       277\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
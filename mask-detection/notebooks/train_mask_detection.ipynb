{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train-mask-detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soOetXKz0Jt2",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_IGvnYFz9NM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVYk8-8b2q0C",
        "colab_type": "text"
      },
      "source": [
        "## Setup notebook parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddIhdddt2xjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train parameters\n",
        "INIT_LR = 1e-4\n",
        "EPOCHS  = 20\n",
        "BS      = 32\n",
        "\n",
        "# Data parameters\n",
        "data_path = '/content/drive/My Drive/covid-19/dataset/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icj9GBio2g74",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk__D0O02j8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_paths():\n",
        "  file_paths_and_labels = []\n",
        "  subfolders            = [x[0] for x in os.walk(data_path)][1:]\n",
        "  \n",
        "  for folder in subfolders:\n",
        "    label = folder.split('/')[-1]\n",
        "    \n",
        "    [file_paths_and_labels.append((folder + '/' + file_name, label)) for file_name in os.listdir(folder)]\n",
        "\n",
        "  return file_paths_and_labels\n",
        "\n",
        "def load_images():\n",
        "  file_paths_and_labels = load_image_paths()\n",
        "  data   = []\n",
        "  labels = []\n",
        "  \n",
        "  total_images = len(file_paths_and_labels)\n",
        "\n",
        "  for i, (image_path, label) in enumerate(file_paths_and_labels):\n",
        "    print(\"Loading images: %.2f%%\" % (100*(i+1)/total_images))\n",
        "\n",
        "    image = load_img(image_path, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = preprocess_input(image)\n",
        "\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        "  \n",
        "  return data, labels\n",
        "\n",
        "data, labels = load_images()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSQIxXmaGhj3",
        "colab_type": "text"
      },
      "source": [
        "## One-Hot encoding and Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx91hC-MGvLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "labels          = label_binarizer.fit_transform(labels)\n",
        "labels          = to_categorical(labels)\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "                                                  test_size=0.20, stratify=labels, random_state=42)\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3E2QPe_LH8t",
        "colab_type": "text"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFy3DH0oLzPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cz8fZb-NagZ",
        "colab_type": "text"
      },
      "source": [
        "## Compile and train model head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtuWKdpJNdYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tvalidation_steps=len(testX) // BS,\n",
        "\tepochs=EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}